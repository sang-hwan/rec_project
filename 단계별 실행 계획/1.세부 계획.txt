아래에 \*\*1단계: 데이터 수집 환경 구축 (초기 1주)\*\*의 구체적인 실행 계획을 단계별로 정리하여 제시합니다.

---

### 📌 **1단계 세부 실행 계획**

**1. X(구 트위터) API 계정 준비 및 설정**

* X 개발자 포털에 접속하여 개인 계정으로 개발자 신청을 진행합니다.
* API 사용 목적을 명확히 작성하여 승인 절차를 빠르게 통과할 수 있도록 합니다.
* 승인 완료 후 Developer Dashboard에 접속하여 API Key, Secret Key, Access Token, Access Token Secret 등을 안전하게 저장합니다.

**2. 자동화 트윗 수집 프로그램 환경 설정**

* Python 개발 환경을 설치 및 설정합니다. (Anaconda, 가상 환경 등)
* API 접근을 위한 라이브러리(twscrape 또는 Tweepy 등)를 선택하여 설치합니다.
* 라이브러리의 공식 문서를 참고하여 API 연결 테스트를 통해 정상 접근 여부를 확인합니다.
* 수집 가능한 데이터의 종류(트윗 본문, 작성 시간, 좋아요 수, 리트윗 수 등)를 사전에 정의하여 수집 목표를 구체화합니다.

**3. 팔로우 중인 계정 목록 정리 및 분류**

* 현재 본인이 팔로우 중인 계정을 모두 추출하고, 주식 투자와 관련하여 유의미한 계정들을 선별합니다.
* 선별된 계정들을 세부 분류 기준(예: 주식 전문가, 기관 투자자, 경제 전문 언론, 주요 경제 인플루언서 등)에 따라 명확히 구분하여 목록화합니다.
* 해당 목록을 텍스트 또는 Excel 형태로 정리하여 관리하며, 추후 트윗 수집 프로그램에 쉽게 적용할 수 있도록 합니다.

**4. 데이터 수집 로직 설계**

* 앞서 정리한 팔로우 목록을 활용하여, 수집 빈도 및 주기(일 1회 또는 필요에 따라 여러 차례)를 결정합니다.
* 수집할 트윗의 기간과 양(예: 최근 하루치 트윗, 인기 있는 트윗만 수집)을 명확히 합니다.
* API의 호출 한도(rate limit)를 확인하여 무리 없이 데이터를 안정적으로 수집할 수 있도록 호출 주기를 조정합니다.

**5. 데이터 저장 및 관리 환경 구축**

* 데이터베이스 또는 데이터 관리 시스템을 선정합니다. (SQLite, PostgreSQL, Notion 등)
* 수집된 데이터의 필수 정보를 정리할 수 있는 데이터 구조(스키마)를 사전에 정의합니다.
* 프로그램에서 수집한 데이터를 정해진 데이터 관리 시스템에 자동으로 저장할 수 있도록 데이터 연동 구조를 설정합니다.

**6. 자동화 스크립트 및 스케줄링**

* 앞서 설계된 데이터 수집 로직을 Python 프로그램으로 구현합니다.
* 프로그램의 실행 안정성을 점검하고, 오류 발생 시 예외 처리를 위한 로직을 추가하여 안정성을 높입니다.
* 스케줄링 도구(예: cron job, Windows 작업 스케줄러)를 활용하여 데이터 수집 프로그램이 매일 일정한 시간에 자동으로 실행되도록 설정합니다.

**7. 초기 테스트 및 환경 점검**

* 설정된 자동 수집 프로그램을 1\~2일 동안 시험 가동하여 데이터를 정상적으로 수집 및 저장하는지 점검합니다.
* 수집된 데이터를 확인하여 품질과 양을 평가하고, 필요한 경우 프로그램의 세부 조건을 조정하여 수집 효율성을 높입니다.
* 초기 시험 가동 결과를 바탕으로 데이터 수집 환경을 최종 점검하여 안정성을 확보하고, 본격적인 수집 준비를 마칩니다.
