import asyncio  # ë¹„ë™ê¸° ì‘ì—…ì„ ì²˜ë¦¬í•˜ê¸° ìœ„í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬
import json  # JSON ë°ì´í„°ë¥¼ ì½ê³  ì“°ê¸° ìœ„í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬
import pandas as pd  # CSV ë°ì´í„°ë¥¼ ì½ê³  DataFrameì„ ë‹¤ë£¨ê¸° ìœ„í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬
import requests  # HTTP ìš”ì²­ì„ ë³´ë‚´ê¸° ìœ„í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬
from datetime import datetime, timedelta  # ë‚ ì§œì™€ ì‹œê°„ì„ ë‹¤ë£¨ê¸° ìœ„í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬
from twscrape import API, gather  # íŠ¸ìœ„í„°ì—ì„œ ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•˜ê¸° ìœ„í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬
from x_client_transaction.utils import generate_headers, handle_x_migration, get_ondemand_file_url  # X í—¤ë” ìƒì„± ë„êµ¬
from x_client_transaction import ClientTransaction  # íŠ¸ëœì­ì…˜ IDë¥¼ ë™ì ìœ¼ë¡œ ìƒì„±í•˜ëŠ” í´ë˜ìŠ¤
import re
from collections import Counter

# ì…ë ¥ ë°ì´í„° í˜•íƒœ: JSON íŒŒì¼ì— ì €ì¥ëœ ê³„ì • ì •ë³´
# ì²˜ë¦¬ ê³¼ì •: JSON íŒŒì¼ì—ì„œ ë°ì´í„°ë¥¼ ì½ì–´ ë”•ì…”ë„ˆë¦¬ í˜•íƒœë¡œ ë³€í™˜
# ë°˜í™˜ ë°ì´í„° í˜•íƒœ: {'user_1': {id, pw, email, email_pw}, ...} í˜•íƒœì˜ ë”•ì…”ë„ˆë¦¬
def load_accounts(account_file='account.json'):
    with open(account_file, 'r') as f:  # íŒŒì¼ ì—´ê¸°
        accounts = json.load(f)['x']  # JSON ë°ì´í„°ë¥¼ ë”•ì…”ë„ˆë¦¬ë¡œ ë¡œë“œ
    return accounts  # ë¡œë“œëœ ê³„ì • ì •ë³´ ë°˜í™˜

# X-Client-Transaction-IDë¥¼ ë™ì ìœ¼ë¡œ ìƒì„±í•˜ì—¬ ë°˜í™˜í•˜ëŠ” í•¨ìˆ˜
def generate_transaction_id():
    session = requests.Session() # HTTP ìš”ì²­ì„ ë³´ë‚´ê³  ì‘ë‹µì„ ë°›ì„ ë•Œ ì„¸ì…˜ì„ ìœ ì§€í•˜ê¸° ìœ„í•œ ê°ì²´ ìƒì„±
    session.headers = generate_headers() # ì›¹ ë¸Œë¼ìš°ì €ì™€ ìœ ì‚¬í•œ ìš”ì²­ í—¤ë”ë¥¼ ì„¤ì •í•˜ì—¬, ì‹¤ì œ ì‚¬ìš©ì ìš”ì²­ì²˜ëŸ¼ ë³´ì´ê²Œ ë§Œë“¦
    home_page_response = handle_x_migration(session=session) # X.com ì›¹ì‚¬ì´íŠ¸ì˜ ë©”ì¸ í˜ì´ì§€ë¥¼ ë¶ˆëŸ¬ì™€ ì´ˆê¸° ì„¸ì…˜ê³¼ ì¿ í‚¤ë¥¼ í™•ë³´
    ondemand_file_url = get_ondemand_file_url(home_page_response) # ì´ˆê¸° í˜ì´ì§€ HTMLì—ì„œ íŠ¹ì • JavaScript íŒŒì¼(ondemand.s)ì˜ URLì„ ì¶”ì¶œ
    ondemand_file = session.get(url=ondemand_file_url) # ì¶”ì¶œëœ URLì—ì„œ í•´ë‹¹ JavaScript íŒŒì¼ì„ ë‹¤ìš´ë¡œë“œ
    ct = ClientTransaction(home_page_response, ondemand_file.content) # ìœ„ì˜ ë©”ì¸ í˜ì´ì§€ ì‘ë‹µê³¼ ë‹¤ìš´ë¡œë“œí•œ íŒŒì¼ ë‚´ìš©ì„ ê¸°ë°˜ìœ¼ë¡œ, íŠ¸ìœ„í„°ê°€ ìš”êµ¬í•˜ëŠ” íŠ¹ìˆ˜í•œ í—¤ë”(X-Client-Transaction-ID)ë¥¼ ìƒì„±í•˜ëŠ” ê°ì²´ ì´ˆê¸°í™”
    return ct.generate_transaction_id(method="POST", path="/1.1/onboarding/task.json") # ì§€ì •ëœ API ê²½ë¡œì™€ HTTP ë©”ì„œë“œ(POST)ì— ë§ëŠ” ê³ ìœ  íŠ¸ëœì­ì…˜ IDë¥¼ ìƒì„±í•˜ì—¬ ë°˜í™˜

# ë¡œê·¸ì¸ ìƒíƒœë¥¼ ì²´í¬í•˜ê³ , í•„ìš”í•˜ë©´ ë¡œê·¸ì¸í•˜ëŠ” ë¹„ë™ê¸° í•¨ìˆ˜
async def ensure_accounts_logged_in_with_cookies(api, accounts):
    # accounts ë”•ì…”ë„ˆë¦¬ì—ì„œ ê° ê³„ì •ì„ ì¶”ê°€(ì¿ í‚¤ ê¸°ë°˜)
    for key, acc in accounts.items():
        await api.pool.add_account(
            acc['id'], acc['pw'], acc['email'], acc['email_pw'], cookies=acc['cookies']
        )

    # ëª¨ë“  ê³„ì •ì˜ í˜„ì¬ ìƒíƒœ ì¡°íšŒ
    statuses = await api.pool.accounts
    # ë¡œê·¸ì¸ë˜ì§€ ì•Šì€ ê³„ì •ë§Œ ì„ ë³„
    logged_out_accounts = [acc for acc in statuses if not acc.logged_in]
    
    if not logged_out_accounts:
        print("âœ… ëª¨ë“  ê³„ì •ì´ ì´ë¯¸ ë¡œê·¸ì¸ ìƒíƒœì…ë‹ˆë‹¤.")
        return

    if len(logged_out_accounts) == len(statuses):
        # ëª¨ë“  ê³„ì •ì´ ë¡œê·¸ì•„ì›ƒ ìƒíƒœì¸ ê²½ìš° ì „ì²´ ë¡œê·¸ì¸ ì‹œë„
        print("ğŸ”‘ ëª¨ë“  ê³„ì •ì´ ë¡œê·¸ì•„ì›ƒ ìƒíƒœì…ë‹ˆë‹¤. ì „ì²´ ê³„ì • ë¡œê·¸ì¸ ìˆ˜í–‰ ì¤‘...")
        await api.pool.login_all()
    else:
        # ì¼ë¶€ ê³„ì •ë§Œ ë¡œê·¸ì•„ì›ƒ ìƒíƒœì¸ ê²½ìš° ì„ íƒì  ê°œë³„ ë¡œê·¸ì¸
        print(f"ğŸ”„ {len(logged_out_accounts)}ê°œ ê³„ì •ì´ ë¡œê·¸ì•„ì›ƒ ìƒíƒœì…ë‹ˆë‹¤. ê°œë³„ ì¬ë¡œê·¸ì¸ ìˆ˜í–‰ ì¤‘...")
        for acc in logged_out_accounts:
            await api.pool.relogin(acc.username)
            
    # ìµœì¢… ìƒíƒœ ì¬í™•ì¸
    final_statuses = await api.pool.accounts
    failed_accounts = [acc for acc in final_statuses if not acc.logged_in]
    
    if failed_accounts:
        failed_names = [acc.username for acc in failed_accounts]
        print(f"âš ï¸ ë‹¤ìŒ ê³„ì •ë“¤ì€ ë¡œê·¸ì¸ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤: {failed_names}")
    else:
        print("âœ… ëª¨ë“  ê³„ì • ë¡œê·¸ì¸ ì„±ê³µ!")
        
# íŠ¸ìœ— ë³¸ë¬¸ì—ì„œ í•µì‹¬ í‚¤ì›Œë“œë¥¼ ì¶”ì¶œí•˜ì—¬ ë¯¸ë””ì–´ ì„¤ëª… ìƒì„±í•˜ëŠ” í•¨ìˆ˜
def generate_assumptive_description(tweet_text, media_type):
    # ì˜ë¬¸ê³¼ í•œê¸€ ë‹¨ì–´ ëª¨ë‘ í¬í•¨, ë¹ˆë„ ë†’ì€ ë‹¨ì–´ ì¶”ì¶œ
    words = re.findall(r'\b[ê°€-í£a-zA-Z0-9]+\b', tweet_text)
    most_common_words = [word for word, count in Counter(words).most_common(3)]
    keywords = ', '.join(most_common_words)
    if media_type == "image":
        return f"íŠ¸ìœ— ë³¸ë¬¸ê³¼ ê´€ë ¨ëœ ì´ë¯¸ì§€ (í‚¤ì›Œë“œ: {keywords} ê´€ë ¨ ì´ë¯¸ì§€ë¡œ ì¶”ì •ë¨)"
    elif media_type == "video":
        return f"íŠ¸ìœ— ë³¸ë¬¸ê³¼ ê´€ë ¨ëœ ì˜ìƒ (í‚¤ì›Œë“œ: {keywords} ê´€ë ¨ ì˜ìƒìœ¼ë¡œ ì¶”ì •ë¨)"
    else:
        return "íŠ¸ìœ— ë³¸ë¬¸ê³¼ ê´€ë ¨ëœ ë¯¸ë””ì–´ (ì •í™•í•œ ìœ í˜• ë¯¸í™•ì¸)"

# íŠ¹ì • ê³„ì •ì—ì„œ íŠ¹ì • ê¸°ê°„ ë™ì•ˆ íŠ¸ìœ—ì„ ìˆ˜ì§‘í•˜ëŠ” ë¹„ë™ê¸° í•¨ìˆ˜ (ëª¨ë“  íŠ¸ìœ— ìœ í˜• í¬í•¨)
async def collect_tweets(api, target_account, start_time, end_time, daily_limit=50):
    user_handle = target_account.replace('@', '')
    user = await api.user_by_login(user_handle) # ì‚¬ìš©ì ì •ë³´ ì¡°íšŒ
    
    try:
        tweets = await gather(api.user_tweets(user.id, limit=daily_limit))
    except Exception as e:
        print(f"âš ï¸ íŠ¸ìœ— ìˆ˜ì§‘ ì¤‘ ì—ëŸ¬ ë°œìƒ ({target_account}): {str(e)}")
        tweets = []

    collected_tweets = []  # ìˆ˜ì§‘ëœ íŠ¸ìœ—ì„ ì €ì¥í•  ë¦¬ìŠ¤íŠ¸

    for tweet in tweets:
        if start_time <= tweet.date <= end_time: # ì§€ì •í•œ ë‚ ì§œ ë²”ìœ„ ë‚´ íŠ¸ìœ—ë§Œ ìˆ˜ì§‘
            media_contents = []
            if tweet.media:
                for media in tweet.media:
                    media_type = "image" if media.type == "photo" else "video" if media.type == "video" else "other"
                    media_contents.append({
                        "type": media_type,
                        "url": media.url,
                        "description": generate_assumptive_description(tweet.rawContent, media_type)
                    })

            tweet_data = {
                'tweet_id': tweet.id,
                'user_id': tweet.user.id,
                'username': tweet.user.username,
                'content': tweet.rawContent,
                'created_at': tweet.date.strftime("%Y-%m-%d %H:%M:%S"),
                'retweets': tweet.retweetCount,
                'likes': tweet.likeCount,
                'replies': tweet.replyCount,
                'quotes': tweet.quoteCount,
                'url': tweet.url,
                'media_contents': media_contents,
                'scraped_at': datetime.utcnow().strftime("%Y-%m-%d %H:%M:%S")
            }

            collected_tweets.append(tweet_data) # íŠ¸ìœ— ë°ì´í„°ë¥¼ ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€
            
    # ìš”ì²­ ê°„ê²©ì„ ì¶©ë¶„íˆ í™•ë³´ (ìµœì†Œ 10ì´ˆ)
    print(f"{target_account} íŠ¸ìœ— ìˆ˜ì§‘ ì™„ë£Œ. ë‹¤ìŒ ìš”ì²­ì„ ìœ„í•´ 10ì´ˆ ëŒ€ê¸°í•©ë‹ˆë‹¤.")
    await asyncio.sleep(10)

    return collected_tweets

# ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜
async def main():
    accounts = load_accounts()  # ê³„ì • ì •ë³´ ë¡œë“œ
    api = API()  # íŠ¸ìœ— ìˆ˜ì§‘ API ê°ì²´ ìƒì„±

    # ë¡œê·¸ì¸ ìƒíƒœ ì²´í¬ ë° ë¡œê·¸ì¸ ìˆ˜í–‰
    await ensure_accounts_logged_in_with_cookies(api, accounts)

    # ë™ì  í—¤ë” ìƒì„± ë° ì¶”ê°€
    # X-Client-Transaction-IDëŠ” ìë™í™” íƒì§€ íšŒí”¼ë¥¼ ìœ„í•œ ê³ ìœ  ì‹ë³„ìì´ë©°, ë§¤ ìš”ì²­ë§ˆë‹¤ ë™ì ìœ¼ë¡œ ìƒì„±í•˜ì§€ ì•Šìœ¼ë©´ ë°´ ìœ„í—˜ì´ ì»¤ì§ˆ ìˆ˜ ìˆìŒ
    transaction_id = generate_transaction_id()
    api.headers["x-client-transaction-id"] = transaction_id

    following_df = pd.read_csv('following_list.csv')  # CSV íŒŒì¼ì—ì„œ ê³„ì • ëª©ë¡ ë¡œë“œ
    target_accounts = following_df['account_id'].tolist()  # DataFrameì—ì„œ ê³„ì • ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜

    end_time = datetime.utcnow()  # ìˆ˜ì§‘ ì¢…ë£Œ ì‹œê°„
    start_time = end_time - timedelta(days=1)  # ìˆ˜ì§‘ ì‹œì‘ ì‹œê°„ (í•˜ë£¨ ì „)

    all_tweets = []  # ëª¨ë“  íŠ¸ìœ—ì„ ì €ì¥í•  ë¦¬ìŠ¤íŠ¸

    for idx, account in enumerate(target_accounts):  # ëª¨ë“  ê³„ì •ì„ ìˆœíšŒ
        print(f"[{idx+1}/{len(target_accounts)}] Collecting tweets from {account}...")
        tweets = await collect_tweets(api, account, start_time, end_time)  # íŠ¸ìœ— ìˆ˜ì§‘
        all_tweets.extend(tweets)  # ê²°ê³¼ ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€

    # ìµœì¢… ìˆ˜ì§‘ëœ íŠ¸ìœ—ì„ JSON íŒŒì¼ë¡œ ì €ì¥
    if all_tweets:
        filename = f'collected_tweets_{end_time.strftime("%Y%m%d%H%M")}.json'
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(all_tweets, f, ensure_ascii=False, indent=2)

        print(f"\nì´ {len(all_tweets)}ê°œì˜ íŠ¸ìœ—ì„ '{filename}'ì— ì €ì¥í–ˆìŠµë‹ˆë‹¤.")
    else:
        print("ìˆ˜ì§‘ëœ íŠ¸ìœ—ì´ ì—†ìŠµë‹ˆë‹¤.")

# ë¹„ë™ê¸° ë©”ì¸ í•¨ìˆ˜ ì‹¤í–‰
if __name__ == '__main__':
    asyncio.run(main())
